import torch
from torch import nn
import pandas as pd
import torch.optim as optim
import torch.nn.functional as F
from torch.nn.utils.rnn import pad_sequence
import copy
from torch.utils.data import Dataset, DataLoader
import gc
import random
import wandb



device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)
END = '>'
START = '<'
PADDING = '_'
TEACHER_FORCING_RATIO = 0.5

train_csv = "/kaggle/input/dataset/aksharantar_sampled/tel/tel_train.csv"
test_csv = "/kaggle/input/dataset/aksharantar_sampled/tel/tel_test.csv"
val_csv = "/kaggle/input/dataset/aksharantar_sampled/tel/tel_valid.csv"

train_df = pd.read_csv(train_csv, header=None)
test_df = pd.read_csv(test_csv, header=None)
val_df = pd.read_csv(val_csv, header=None)
train_x, train_y = train_df[0].to_numpy(), train_df[1].to_numpy()
val_x, val_y = val_df[0].to_numpy(), val_df[1].to_numpy()


def padding_to_string(source_data, max_length, length):
    strings = []
    for i in range(length):
        str_padding = START + source_data[i]   # adding start token and end token
        str_padding = str_padding + END
        str_padding = str_padding[:max_length]       #   
        padding_length = max_length - len(str_padding)
        if(padding_length>0):
            str_padding = str_padding + PADDING * padding_length        
        strings.append(str_padding)
    return strings


def generate_string_to_sequence(source_data, char_to_index, length):
    source_sequences = []
    for i in range(length):
        index=[]
        for j in source_data[i]:
            index.append(char_to_index[j])
        source_sequences.append(torch.tensor(index, device=device))
    source_sequences = pad_sequence(source_sequences, batch_first=True, padding_value=2)
    return source_sequences


def character_adding(c, data, source_char_index, source_chars, source_index_char):
    if data[source_char_index].get(c) is None:
        data[source_chars].append(c)              
        idx = len(data[source_chars]) - 1
        data[source_char_index][c] = idx
        data[source_index_char][idx] = c



def preprocess_data(source_data, target_data, length_data):
    data = {
        "source_chars": [START, END, PADDING],
        "target_chars": [START, END, PADDING],
        "source_char_index": {START: 0, END:1, PADDING:2},
        "source_index_char": {0:START, 1: END, 2:PADDING},
        "target_char_index": {START: 0, END:1, PADDING:2},
        "target_index_char": {0:START, 1: END, 2:PADDING},
        "source_len": 3,
        "target_len": 3,
        "source_data": source_data,
        "target_data": target_data,
        "source_data_seq": [],
        "target_data_seq": []
    }
    
    x_max_length=0
    y_max_length=0
    for i in range(len(source_data)):   # finding maximum length input and output
        x_max_length=max(x_max_length,len(source_data[i]))
        y_max_length=max(y_max_length,len(target_data[i]))
        
        
    data["INPUT_MAX_LENGTH"] = x_max_length + 2   # adding 2 for start and end
    data["OUTPUT_MAX_LENGTH"] = y_max_length + 2

    
    padded_source_strings=padding_to_string(source_data, data["INPUT_MAX_LENGTH"], length_data)
    padded_target_strings = padding_to_string(target_data, data["OUTPUT_MAX_LENGTH"], length_data)
    
    for i in range(length_data):   # for every string 
        for c in padded_source_strings[i]:        # for every character in string 
            character_adding(c, data, "source_char_index", "source_chars", "source_index_char")
        for c in padded_target_strings[i]:
            character_adding(c, data, "target_char_index", "target_chars", "target_index_char")

    data['source_data_seq'] = generate_string_to_sequence(padded_source_strings,  data['source_char_index'], len(padded_source_strings))
    data['target_data_seq'] = generate_string_to_sequence(padded_target_strings,  data['target_char_index'], len(padded_source_strings))
    
    return data

def get_cell_type(state):
    if(state == "RNN"):
        return nn.RNN
    else:
        if(state=="GRU"):
            return nn.GRU
        elif(state=="LSTM"):
            return nn.LSTM

        
class Attention(nn.Module):
    def __init__(self, hidden_size):
        super(Attention, self).__init__()
        self.Wa = nn.Linear(hidden_size, hidden_size)
        self.Ua = nn.Linear(hidden_size, hidden_size)
        self.Va = nn.Linear(hidden_size, 1)

    def forward(self, query, keys):
        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))
        keys = keys.permute(1,0,2)
        context = torch.bmm(weights, keys)
        scores = scores.squeeze().unsqueeze(1)
        weights = F.softmax(scores, dim=0)
        weights = weights.permute(2,1,0)
        return context, weights


class Encoder(nn.Module):
    def __init__(self, h_params, data, device, p_dropout, p_cell, p_hidden_layers, p_no_of_layers, p_char_dim, length):
        super(Encoder, self).__init__()
        self.device=device
        self.data = data
        self.h_params = h_params
        self.embedding = nn.Embedding(length, p_char_dim)
        self.cell = get_cell_type(p_cell)(p_char_dim, p_hidden_layers, num_layers=p_no_of_layers, dropout= p_dropout, batch_first=True)
        
    def forward(self, input , encoder_curr_state, input_length, batch_size, hidden_neurons, no_of_layers):
        encoder_states  = torch.zeros(input_length, no_of_layers, batch_size, hidden_neurons, device=device )
        for i in range(input_length):
            current_input = input[:, i].view(batch_size,1)
            _, encoder_curr_state = self.forward_step(current_input, encoder_curr_state)
            if self.h_params["cell_type"] == "GRU":
                encoder_states[i] = encoder_curr_state
                
            elif(self.h_params["cell_type"] == "LSTM"):
                encoder_states[i] = encoder_curr_state[1]
            else:
                encoder_states[i] = encoder_curr_state
        return encoder_states, encoder_curr_state
    
    def forward_step(self, current_input, prev_state):
        return self.cell(self.embedding(current_input), prev_state)
        
    def getInitialState(self, no_of_layers, batchsize, hidden_layers):
        return torch.zeros(no_of_layers, batchsize, hidden_layers, device=self.device)

    
class Decoder(nn.Module):
    def __init__(self, h_params, data, device, p_dropout, p_cell, p_hidden_layers, p_no_of_layers, p_char_dim, length):
        super(Decoder, self).__init__()
        self.h_params = h_params
        self.data = data
        self.device = device
        self.attention = Attention(p_hidden_layers).to(device)
        self.embedding = nn.Embedding(length, p_char_dim)
        self.cell = get_cell_type(p_cell)(p_char_dim + p_hidden_layers, h_params["hidden_layer_neurons"], num_layers=p_no_of_layers,dropout= p_dropout, batch_first=True)
        self.fc = nn.Linear(p_hidden_layers, length)
        self.softmax = nn.LogSoftmax(dim=2)

    def forward(self, decoder_current_state, encoder_final_layers, target_batch, loss_fn, batch_size, y_max_length, tf=True):
        decoder_current_input = torch.full((batch_size,1),self.data["target_char_index"][START], device=self.device)
        embd_input = self.embedding(decoder_current_input)
        curr_embd = F.relu(embd_input)
        decoder_actual_output = []
        attentions = []
        loss = 0
        use_teacher_forcing = False
        if(tf==True):
            if(random.random()<TEACHER_FORCING_RATIO):
                use_teacher_forcing=True
            else:
                use_teacher_forcing=False

        for i in range(y_max_length):
            decoder_output, decoder_current_state, attn_weights = self.forward_step(decoder_current_input, decoder_current_state, encoder_final_layers, self.h_params["cell_type"])
            attentions.append(attn_weights)
            topv, topi = decoder_output.topk(1)
            decoder_current_input = topi.squeeze().detach()
            decoder_actual_output.append(decoder_current_input)
            curr_target_chars = target_batch[:, i]
            if(target_batch==None):
                decoder_current_input = decoder_current_input.view(batch_size, 1)
            elif(i<y_max_length-1):
                if use_teacher_forcing:
                    decoder_current_input = target_batch[:, i+1].view(batch_size, 1)
                else:
                    decoder_current_input = decoder_current_input.view(batch_size, 1)
                decoder_output = decoder_output[:, -1, :]
                loss+=(loss_fn(decoder_output, curr_target_chars))
            else
                decoder_output = decoder_output[:, -1, :]
                loss+=(loss_fn(decoder_output, curr_target_chars))

        decoder_actual_output = torch.cat(decoder_actual_output,dim=0).view(y_max_length, batch_size).transpose(0,1)

        correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()
        return decoder_actual_output, attentions, loss, correct
    
    def forward_step(self, current_input, prev_state, encoder_final_layers, cell):
        embd_input = self.embedding(current_input)
        if(cell== "LSTM"):
            context , attn_weights = self.attention(prev_state[1][-1,:,:], encoder_final_layers)
        else:
            context , attn_weights = self.attention(prev_state[-1,:,:], encoder_final_layers)
        curr_embd = F.relu(embd_input)
        input_gru = torch.cat((curr_embd, context), dim=2)
        output, prev_state = self.cell(input_gru, prev_state)
        output = self.softmax(self.fc(output))
        return output, prev_state, attn_weights

class MyDataset(Dataset):
    def __init__(self, data):
        self.source_data_seq = data[0]
        self.target_data_seq = data[1]
    
    def __len__(self):
        return len(self.source_data_seq)
    
    def __getitem__(self, idx):
        source_data = self.source_data_seq[idx]
        target_data = self.target_data_seq[idx]
        return source_data, target_data

   
def loss_calculation(correct_predictions, total_predictions, total_loss, number_of_batches):
    accu=correct_predictions/total_predictions
    loss=total_loss/number_of_batches
    return accu, loss


def evaluate(encoder, decoder, data, dataloader, device, h_params, loss_fn, use_teacher_forcing = False):
    correct_predictions = 0
    total_loss = 0
    total_predictions = len(dataloader.dataset)
    number_of_batches = len(dataloader)
    with torch.no_grad():
        for batch_num, (source_batch, target_batch) in enumerate(dataloader):
            
            encoder_initial_state = encoder.getInitialState(h_params["number_of_layers"], h_params["batch_size"],h_params["hidden_layer_neurons"])
            if h_params["cell_type"] == "LSTM":
                encoder_initial_state = (encoder_initial_state, encoder.getInitialState(h_params["number_of_layers"], h_params["batch_size"],h_params["hidden_layer_neurons"]))
            encoder_states, encoder_final_state = encoder(source_batch, encoder_initial_state, data["INPUT_MAX_LENGTH"], h_params["batch_size"], h_params["hidden_layer_neurons"], h_params["number_of_layers"])

            decoder_current_state = encoder_final_state
            encoder_final_layer_states = encoder_states[:, -1, :, :]

            loss = 0
            correct = 0

            decoder_output, attentions, loss, correct = decoder(decoder_current_state, encoder_final_layer_states, target_batch, loss_fn,h_params["batch_size"], data["OUTPUT_MAX_LENGTH"], use_teacher_forcing)
            correct_predictions+=correct
            total_loss +=loss
        

        accuracy, total_loss = loss_calculation(correct_predictions, total_predictions, total_loss, number_of_batches)
        # accuracy = correct_predictions / total_predictions
        # total_loss /= number_of_batches
    
    return accuracy, total_loss


def make_strings(data, source, target, output):
    source_string = ""
    target_string = ""
    output_string = ""
    for i in source:
        source_string+=(data['source_index_char'][i.item()])
    for i in target:
        target_string+=(data['target_index_char'][i.item()])
    for i in output:
        output_string+=(data['target_index_char'][i.item()])
    return source_string, target_string, output_string


def optimizer_fun(h_params, encoder, decoder):
    x=[]
    y=[]
    if(h_params["optimizer"]=="adam"):
        x=optim.Adam(encoder.parameters(), lr=h_params["learning_rate"])
        y=optim.Adam(decoder.parameters(), lr=h_params["learning_rate"])
    elif(h_params["optimizer"]=="nadam"):
        x=optim.NAdam(encoder.parameters(), lr=h_params["learning_rate"])
        y=optim.NAdam(decoder.parameters(), lr=h_params["learning_rate"])
    return x,y                 

def train_loop(encoder, decoder,h_params, data, data_loader, device, val_dataloader, y_max_length, no_of_epochs, batchsize, cell, total_pre, batch_total, tf=True):
    
    encoder_optimizer, decoder_optimizer = optimizer_fun(h_params, encoder, decoder)

    loss_fn = nn.NLLLoss()
    
    total_predictions = total_pre
    total_batches = batch_total
    
    for ep in range(no_of_epochs):
        total_correct = 0
        total_loss = 0
        for batch_num, (source_batch, target_batch) in enumerate(data_loader):
            loss = 0
            correct = 0
            encoder_initial_state = encoder.getInitialState(h_params["number_of_layers"], h_params["batch_size"],h_params["hidden_layer_neurons"])
            if(cell== "LSTM"):
                encoder_initial_state = (encoder_initial_state, encoder.getInitialState(h_params["number_of_layers"], h_params["batch_size"],h_params["hidden_layer_neurons"]))
            encoder_states, encoder_final_state = encoder(source_batch,encoder_initial_state, data["INPUT_MAX_LENGTH"], h_params["batch_size"], h_params["hidden_layer_neurons"], h_params["number_of_layers"])
            
            decoder_current_state = encoder_final_state
            encoder_final_layer_states = encoder_states[:, -1, :, :]
            decoder_output, attentions, loss, correct = decoder(decoder_current_state, encoder_final_layer_states, target_batch, loss_fn, h_params["batch_size"], data["OUTPUT_MAX_LENGTH"], tf)
            total_loss += loss.item()/data["OUTPUT_MAX_LENGTH"]
            total_correct +=correct
            encoder_optimizer.zero_grad()
            decoder_optimizer.zero_grad()
            loss.backward()
            encoder_optimizer.step()
            decoder_optimizer.step()
            
            del encoder_initial_state, encoder_final_layer_states, encoder_states, encoder_final_state, decoder_output, attentions
            torch.cuda.empty_cache()
            gc.collect()
        train_acc, train_loss = loss_calculation(total_correct, total_predictions, total_loss, total_batches)    
        val_acc, val_loss = evaluate(encoder, decoder, data, val_dataloader,device, h_params, loss_fn, False)
        print("ep: ", ep, " train acc:", train_acc, " train loss:", train_loss, " val acc:", val_acc, " val loss:", val_loss.item()/data["OUTPUT_MAX_LENGTH"])
        # wandb.log({"train_accuracy":train_acc, "train_loss":train_loss, "val_accuracy":val_acc, "val_loss":val_loss, "epoch":ep})

def train_val_data(x, y, h_params):
    data_set=[x,y]
    train_val_set=MyDataset(data_set)
    return DataLoader(train_val_set, batch_size=h_params["batch_size"], shuffle=True)

def processing_dataset(train_source, train_target, val_source, val_target, h_params):
    data = preprocess_data(copy.copy(train_source), copy.copy(train_target), len(train_source))

    data["source_len"] = len(data["source_chars"])
    data["target_len"] = len(data["target_chars"])

    # train data set
    train_dataloader = train_val_data(data["source_data_seq"], data['target_data_seq'], h_params)

    # validation data
    val_padded_source_strings=padding_to_string(val_source, data["INPUT_MAX_LENGTH"], len(val_source))
    val_padded_target_strings = padding_to_string(val_target, data["OUTPUT_MAX_LENGTH"], len(val_source))
    
    val_source_sequences = generate_string_to_sequence(val_padded_source_strings, data['source_char_index'], len(val_padded_source_strings))
    val_target_sequences = generate_string_to_sequence(val_padded_target_strings, data['target_char_index'], len(val_padded_target_strings))

    val_dataloader = train_val_data(val_source_sequences, val_target_sequences, h_params)
   
    return train_dataloader, val_dataloader, data


def training_function(h_params, device, train_x, train_y, val_x, val_y, tf=True):
    train_dataloader, val_dataloader, data = processing_dataset(train_x, train_y, val_x, val_y, h_params)
    encoder = Encoder(h_params, data, device, h_params["dropout"], h_params["cell_type"], h_params["hidden_layer_neurons"], h_params["number_of_layers"], h_params["char_embd_dim"], data["source_len"]).to(device)
    decoder = Decoder(h_params, data, device, h_params["dropout"], h_params["cell_type"], h_params["hidden_layer_neurons"], h_params["number_of_layers"], h_params["char_embd_dim"], data["target_len"]).to(device)
    train_loop(encoder, decoder,h_params, data, train_dataloader,device, val_dataloader, data["OUTPUT_MAX_LENGTH"], h_params["epochs"], h_params["batch_size"], h_params["cell_type"], len(train_dataloader.dataset), len(train_dataloader), tf)
    torch.cuda.empty_cache() 
    del encoder
    del decoder
    gc.collect()

sweep_params = {
    'method' : 'bayes',
    'name'   : 'cs23m035_Assignment3_With_Attention',
    'metric' : {
        'goal' : 'maximize',
        'name' : 'val_accuracy',
    },
    'parameters' : {
        'epochs':{'values' : [15, 20]},
        'learning_rate':{'values' : [0.001, 0.0001]},
        'batch_size':{'values':[32,64, 128]},
        'char_embd_dim':{'values' : [64, 128, 256] } ,
        'number_of_layers':{'values' : [1,2,3,4]},
        'optimizer':{'values':['nadam','adam']},
        'cell_type':{'values' : ["RNN","LSTM", "GRU"]},
        'hidden_layer_neurons':{'values': [ 128, 256, 512]},
        'dropout':{'values': [0,0.2, 0.3]}
    }
}

sweep_id = wandb.sweep(sweep=sweep_params, project="cs23m035_Assignment3")
def main():
    torch.cuda.empty_cache()
    gc.collect()
    wandb.init(project="cs23m035_Assignment3" )
    config = wandb.config
    with wandb.init(project="cs23m035_Assignment3", name=f"{config['cell_type']}_{config['optimizer']}_ep_{config['epochs']}_lr_{config['learning_rate']}_embd_{config['char_embd_dim']}_hid_lyr_neur_{config['hidden_layer_neurons']}_bs_{config['batch_size']}_enc_layers_{config['number_of_layers']}_dec_layers_{config['number_of_layers']}_dropout_{config['dropout']}", config=config):
        training_function(config, device, train_x, train_y, val_x, val_y, True)

sweepId=wandb.sweep(sweep_params,project='cs23m035_Assignment3')
wandb.agent(sweepId, main)